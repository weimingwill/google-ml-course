{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CS 20: TensorFlow for Deep Learning - Lecture3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Regresssion Model\n",
    "Solution for simple linear regression example using tf.data\n",
    "\n",
    "Created by Chip Huyen (chiphuyen@cs.stanford.edu)\n",
    "\n",
    "CS20: \"TensorFlow for Deep Learning Research\"\n",
    "\n",
    "cs20.stanford.edu Lecture 03\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL']='2'\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import xlrd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_FILE = 'data/fire_theft.xls'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: read in data from the .xls file\n",
    "book = xlrd.open_workbook(DATA_FILE, encoding_override=\"utf-8\")\n",
    "sheet = book.sheet_by_index(0)\n",
    "data = np.asarray([sheet.row_values(i) for i in range(1, sheet.nrows)])\n",
    "n_samples = sheet.nrows - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  6.2  29. ]\n",
      " [  9.5  44. ]\n",
      " [ 10.5  36. ]\n",
      " [  7.7  37. ]\n",
      " [  8.6  53. ]\n",
      " [ 34.1  68. ]\n",
      " [ 11.   75. ]\n",
      " [  6.9  18. ]\n",
      " [  7.3  31. ]\n",
      " [ 15.1  25. ]\n",
      " [ 29.1  34. ]\n",
      " [  2.2  14. ]\n",
      " [  5.7  11. ]\n",
      " [  2.   11. ]\n",
      " [  2.5  22. ]\n",
      " [  4.   16. ]\n",
      " [  5.4  27. ]\n",
      " [  2.2   9. ]\n",
      " [  7.2  29. ]\n",
      " [ 15.1  30. ]\n",
      " [ 16.5  40. ]\n",
      " [ 18.4  32. ]\n",
      " [ 36.2  41. ]\n",
      " [ 39.7 147. ]\n",
      " [ 18.5  22. ]\n",
      " [ 23.3  29. ]\n",
      " [ 12.2  46. ]\n",
      " [  5.6  23. ]\n",
      " [ 21.8   4. ]\n",
      " [ 21.6  31. ]\n",
      " [  9.   39. ]\n",
      " [  3.6  15. ]\n",
      " [  5.   32. ]\n",
      " [ 28.6  27. ]\n",
      " [ 17.4  32. ]\n",
      " [ 11.3  34. ]\n",
      " [  3.4  17. ]\n",
      " [ 11.9  46. ]\n",
      " [ 10.5  42. ]\n",
      " [ 10.7  43. ]\n",
      " [ 10.8  34. ]\n",
      " [  4.8  19. ]]\n",
      "42\n"
     ]
    }
   ],
   "source": [
    "print(data)\n",
    "print(n_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: create placeholders for input X (number of fire) and label Y (number of theft)\n",
    "X = tf.placeholder(tf.float32, name='X')\n",
    "Y = tf.placeholder(tf.float32, name='Y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: create weight and bias, initialized to 0\n",
    "w = tf.Variable(0.0, name='weights')\n",
    "b = tf.Variable(0.0, name='bias')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: build model to predict Y\n",
    "Y_predicted = X * w + b "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 5: use the square error as the loss function\n",
    "loss = tf.square(Y - Y_predicted, name='loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 6: using gradient descent with learning rate of 0.01 to minimize loss\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.001).minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: 2069.6319333978354\n",
      "Epoch 1: 2117.0123581953535\n",
      "Epoch 2: 2092.302723001866\n",
      "Epoch 3: 2068.5080461938464\n",
      "Epoch 4: 2045.591184088162\n",
      "Epoch 5: 2023.5146448101316\n",
      "Epoch 6: 2002.2447619835536\n",
      "Epoch 7: 1981.748338803649\n",
      "Epoch 8: 1961.9944411260742\n",
      "Epoch 9: 1942.9520116143283\n",
      "Epoch 10: 1924.5930823644712\n",
      "Epoch 11: 1906.8898800636332\n",
      "Epoch 12: 1889.8164505837929\n",
      "Epoch 13: 1873.347133841543\n",
      "Epoch 14: 1857.4588400604468\n",
      "Epoch 15: 1842.1278742424079\n",
      "Epoch 16: 1827.332495119955\n",
      "Epoch 17: 1813.0520579712022\n",
      "Epoch 18: 1799.2660847636982\n",
      "Epoch 19: 1785.9562132299961\n",
      "Epoch 20: 1773.1024853109072\n",
      "Epoch 21: 1760.689129482884\n",
      "Epoch 22: 1748.6984157081515\n",
      "Epoch 23: 1737.1138680398553\n",
      "Epoch 24: 1725.920873066732\n",
      "Epoch 25: 1715.1046249579008\n",
      "Epoch 26: 1704.6500954309377\n",
      "Epoch 27: 1694.5447134910141\n",
      "Epoch 28: 1684.7746311347667\n",
      "Epoch 29: 1675.328450968245\n",
      "Epoch 30: 1666.1935385839038\n",
      "Epoch 31: 1657.3584002084322\n",
      "Epoch 32: 1648.8122658529207\n",
      "Epoch 33: 1640.5440742547091\n",
      "Epoch 34: 1632.5446836102221\n",
      "Epoch 35: 1624.8043315147183\n",
      "Epoch 36: 1617.3126799958602\n",
      "Epoch 37: 1610.0622532456405\n",
      "Epoch 38: 1603.0433557207386\n",
      "Epoch 39: 1596.2479176106197\n",
      "Epoch 40: 1589.668056331575\n",
      "Epoch 41: 1583.2965242617897\n",
      "Epoch 42: 1577.126371285745\n",
      "Epoch 43: 1571.1501190634\n",
      "Epoch 44: 1565.360979151513\n",
      "Epoch 45: 1559.7523780798629\n",
      "Epoch 46: 1554.3184364555138\n",
      "Epoch 47: 1549.0529469620615\n",
      "Epoch 48: 1543.950059985476\n",
      "Epoch 49: 1539.0050282141283\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    # Step 7: initialize the necessary variables, in this case, w and b\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    writer = tf.summary.FileWriter('./graphs/linear_reg', sess.graph)\n",
    "    \n",
    "    # Step 8: train the model\n",
    "    for i in range(50):\n",
    "        total_loss = 0\n",
    "        for x, y in data:\n",
    "            # Session runs train_op and fetch values of loss\n",
    "            _, l = sess.run([optimizer, loss], feed_dict={X: x, Y: y})\n",
    "            total_loss += l\n",
    "        print('Epoch {0}: {1}'.format(i, total_loss/n_samples))\n",
    "        \n",
    "    writer.close()\n",
    "        \n",
    "    # Step 9: output the values of w and b\n",
    "    w_value, b_value = sess.run([w, b])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f95c84eb438>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot the results\n",
    "X, Y = data.T[0], data.T[1]\n",
    "plt.plot(X, Y, 'bo', label='Real data')\n",
    "plt.plot(X, X * w_value + b_value, 'r', label='Predicted data')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimizers\n",
    "tf.train.GradientDescentOptimizer\n",
    "\n",
    "tf.train.AdagradOptimizer\n",
    "\n",
    "tf.train.MomentumOptimizer\n",
    "\n",
    "tf.train.AdamOptimizer\n",
    "\n",
    "tf.train.FtrlOptimizer\n",
    "\n",
    "tf.train.RMSPropOptimizer\n",
    "\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Huber Loss\n",
    "Robust to outliers\n",
    "\n",
    "Intuition: if the difference between the predicted value and the real value is small, square it. If it is large, take its absolute value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def huber_loss(labels, predictions, delta=1.0):\n",
    "    residual = tf.abs(predictions - labels)\n",
    "    condition = tf.less(residual, delta)\n",
    "    small_res = 0.5 * tf.square(residual)\n",
    "    large_res = delta * residual - 0.5 * tf.square(delta)\n",
    "    return tf.select(condition, small_res, large_res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL']='2'\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define paramaters for the model\n",
    "learning_rate = 0.01\n",
    "batch_size = 128\n",
    "n_epochs = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "ename": "PermissionDeniedError",
     "evalue": "/data; Permission denied",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mPermissionDeniedError\u001b[0m                     Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-73-391832ba3b40>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Step 1: Read in data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# using TF Learn's built in function to load MNIST data to the folder data/mnist\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mmnist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_data_sets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/data/mnist'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mone_hot\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py\u001b[0m in \u001b[0;36mread_data_sets\u001b[0;34m(train_dir, fake_data, one_hot, dtype, reshape, validation_size, seed, source_url)\u001b[0m\n\u001b[1;32m    239\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    240\u001b[0m   local_file = base.maybe_download(TRAIN_IMAGES, train_dir,\n\u001b[0;32m--> 241\u001b[0;31m                                    source_url + TRAIN_IMAGES)\n\u001b[0m\u001b[1;32m    242\u001b[0m   \u001b[0;32mwith\u001b[0m \u001b[0mgfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlocal_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    243\u001b[0m     \u001b[0mtrain_images\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mextract_images\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/base.py\u001b[0m in \u001b[0;36mmaybe_download\u001b[0;34m(filename, work_directory, source_url)\u001b[0m\n\u001b[1;32m    196\u001b[0m   \"\"\"\n\u001b[1;32m    197\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mgfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwork_directory\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 198\u001b[0;31m     \u001b[0mgfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMakeDirs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwork_directory\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    199\u001b[0m   \u001b[0mfilepath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwork_directory\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mgfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/lib/io/file_io.py\u001b[0m in \u001b[0;36mrecursive_create_dir\u001b[0;34m(dirname)\u001b[0m\n\u001b[1;32m    372\u001b[0m   \"\"\"\n\u001b[1;32m    373\u001b[0m   \u001b[0;32mwith\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_exception_on_not_ok_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 374\u001b[0;31m     \u001b[0mpywrap_tensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRecursivelyCreateDir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_bytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    375\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    376\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/errors_impl.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, type_arg, value_arg, traceback_arg)\u001b[0m\n\u001b[1;32m    514\u001b[0m             \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    515\u001b[0m             \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc_api\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_Message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 516\u001b[0;31m             c_api.TF_GetCode(self.status.status))\n\u001b[0m\u001b[1;32m    517\u001b[0m     \u001b[0;31m# Delete the underlying status object from memory otherwise it stays alive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    518\u001b[0m     \u001b[0;31m# as there is a reference to status from this from the traceback due to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mPermissionDeniedError\u001b[0m: /data; Permission denied"
     ]
    }
   ],
   "source": [
    "# Step 1: Read in data\n",
    "# using TF Learn's built in function to load MNIST data to the folder data/mnist\n",
    "mnist = input_data.read_data_sets('/data/mnist', one_hot=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: create placeholders for features and labels\n",
    "# each image in the MNIST data is of shape 28*28 = 784\n",
    "# therefore, each image is represented with a 1x784 tensor\n",
    "# there are 10 classes for each image, corresponding to digits 0 - 9. \n",
    "# each lable is one hot vector.\n",
    "X = tf.placeholder(tf.float32, [batch_size, 784], name='X_placeholder') \n",
    "Y = tf.placeholder(tf.int32, [batch_size, 10], name='Y_placeholder')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: create weights and bias\n",
    "# w is initialized to random variables with mean of 0, stddev of 0.01\n",
    "# b is initialized to 0\n",
    "# shape of w depends on the dimension of X and Y so that Y = tf.matmul(X, w)\n",
    "# shape of b depends on Y\n",
    "w = tf.Variable(tf.random_normal(shape=[784, 10], stddev=0.01), name='weights')\n",
    "b = tf.Variable(tf.zeros([1, 10]), name=\"bias\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: build model\n",
    "# the model that returns the logits.\n",
    "# this logits will be later passed through softmax layer\n",
    "logits = tf.matmul(X, w) + b "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 5: define loss function\n",
    "# use cross entropy of softmax of logits as the loss function\n",
    "entropy = tf.nn.softmax_cross_entropy_with_logits(logits=logits, labels=Y, name='loss')\n",
    "loss = tf.reduce_mean(entropy) # computes the mean over all the examples in the batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 6: define training op\n",
    "# using gradient descent with learning rate of 0.01 to minimize loss\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate).minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[8 5 7 7 4 6 2 8 1 5 9 4 7 1 6 2 0 7 8 3 0 3 6 4 3 1 1 9 4 7 0 1 4 0 2 5 8\n",
      " 0 1 6 1 7 5 8 0 0 3 3 1 0 6 2 6 1 1 3 7 7 7 2 5 2 3 7 8 4 6 6 5 4 1 0 6 1\n",
      " 1 7 1 1 6 2 9 9 1 5 9 4 0 7 3 1 4 0 1 6 0 9 2 9 1 9 1 8 8 8 2 8 3 2 2 5 6\n",
      " 0 9 9 4 2 8 5 2 4 9 6 9 3 2 1 4 2]\n",
      "(128,)\n",
      "Average loss epoch 0: 0.0\n",
      "Total time: 0.02180004119873047 seconds\n",
      "Optimization Finished!\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Cannot feed value of shape (128,) for Tensor 'Y_placeholder_1:0', which has shape '(128, 10)'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-72-981ecd005744>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_batches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m         \u001b[0mX_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmnist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnext_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m         \u001b[0maccuracy_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0maccuracy\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mX_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mY_batch\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m         \u001b[0mtotal_correct_preds\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0maccuracy_batch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    903\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    904\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 905\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    906\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    907\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1111\u001b[0m                              \u001b[0;34m'which has shape %r'\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1112\u001b[0m                              (np_val.shape, subfeed_t.name,\n\u001b[0;32m-> 1113\u001b[0;31m                               str(subfeed_t.get_shape())))\n\u001b[0m\u001b[1;32m   1114\u001b[0m           \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_feedable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubfeed_t\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1115\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Tensor %s may not be fed.'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0msubfeed_t\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Cannot feed value of shape (128,) for Tensor 'Y_placeholder_1:0', which has shape '(128, 10)'"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    # to visualize using TensorBoard\n",
    "    writer = tf.summary.FileWriter('./graphs/logistic_reg', sess.graph)\n",
    "\n",
    "    start_time = time.time()\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    n_batches = int(mnist.train.num_examples/batch_size)\n",
    "    for i in range(n_epochs): # train the model n_epochs times\n",
    "        total_loss = 0\n",
    "\n",
    "        for _ in range(n_batches):\n",
    "            X_batch, Y_batch = mnist.train.next_batch(batch_size)\n",
    "            print(Y_batch)\n",
    "            print(Y_batch.shape)            \n",
    "            break\n",
    "            _, loss_batch = sess.run([optimizer, loss], feed_dict={X: X_batch, Y:Y_batch}) \n",
    "            total_loss += loss_batch\n",
    "        print('Average loss epoch {0}: {1}'.format(i, total_loss/n_batches))\n",
    "        break\n",
    "    print('Total time: {0} seconds'.format(time.time() - start_time))\n",
    "\n",
    "    print('Optimization Finished!') # should be around 0.35 after 25 epochs\n",
    "\n",
    "    # test the model\n",
    "    preds = tf.nn.softmax(logits)\n",
    "    correct_preds = tf.equal(tf.argmax(preds, 1), tf.argmax(Y, 1))\n",
    "    accuracy = tf.reduce_sum(tf.cast(correct_preds, tf.float32)) # need numpy.count_nonzero(boolarr) :(\n",
    "    \n",
    "    n_batches = int(mnist.test.num_examples/batch_size)\n",
    "    total_correct_preds = 0\n",
    "        \n",
    "    for i in range(n_batches):\n",
    "        X_batch, Y_batch = mnist.test.next_batch(batch_size)\n",
    "        accuracy_batch = sess.run([accuracy], feed_dict={X: X_batch, Y:Y_batch}) \n",
    "        total_correct_preds += accuracy_batch \n",
    "\n",
    "    print('Accuracy {0}'.format(total_correct_preds/mnist.test.num_examples))\n",
    "\n",
    "    writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
